{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "325a139a911d2709",
   "metadata": {},
   "source": [
    "# QuPath Cell Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623af9dbfe2fb2c2",
   "metadata": {},
   "source": [
    "In this example we create cell segmentations in [QuPath](https://qupath.github.io/), convert them to a binary mask in python, and push both the original image and and cell mask to ManiVault.\n",
    "\n",
    "We use the `OS-2.ndpi` from the [OpenSlide example images](https://openslide.cs.cmu.edu/download/openslide-testdata/Hamamatsu/) as also used in the [QuPath cell detection tutorial](https://qupath.readthedocs.io/en/0.5/docs/tutorials/cell_detection.html). After downloading, the file will automatically be called `OS-2.tiff`.\n",
    "\n",
    "First, we create a cell mask with QuPath\n",
    "\n",
    "1. Open the `OS-2.tiff` file in QuPath\n",
    "2. Create a rectangular annotation (ROI) and export it as on ome.tiff\n",
    "3. Open this new `OS2-ROI.ome.tif` in QuPath\n",
    "4. Segment the cells via `Analyze` > `Cell detection`. First, create a rectangular annocation that covers the entire image, and then ,in the pop-up ,de-select the options \"Include cell nucleus\" and \"Make measurements\". Click \"Run\".\n",
    "6. Export the cell masks to GeoJSON: Select all cell annotations, click `File` > `Export Objects as GeoJSON`, select \"Pretty JSON\" and \"Exclude measurements\" and click \"OK\".\n",
    "\n",
    "\n",
    "OS-2.ndpi in QuPath | ROI with segmeted cells\n",
    "- | -\n",
    "![Full cell image](full_image.png) | ![Cell mask](segmented_cells.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9876db99ec683883",
   "metadata": {},
   "source": [
    "Let's define some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(load_json_file_path):\n",
    "    import json\n",
    "    with open(load_json_file_path) as load_json_file:\n",
    "        loaded_json_file = json.load(load_json_file)\n",
    "    return loaded_json_file\n",
    "\n",
    "def load_tiff(load_tiff_path):\n",
    "    from tifffile import tifffile\n",
    "    return tifffile.imread(load_tiff_path)\n",
    "\n",
    "\n",
    "def extract_mask_from_geojson(geo_json_in, mask_out_shape = (1024, 1024)):\n",
    "    \"\"\"\n",
    "    :param geo_json_in: json file\n",
    "    :param mask_out_shape: optional, Define output raster shape (e.g., 512x512) and transform (identity for simple pixel grid)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    from shapely.geometry import shape\n",
    "    from rasterio.features import rasterize\n",
    "\n",
    "    # Extract polygon geometries\n",
    "    shapes = [shape(feature['geometry']) for feature in geo_json_in['features']]\n",
    "\n",
    "    # Rasterize polygons into mask\n",
    "    mask_out = rasterize(\n",
    "        [(geom, 1) for geom in shapes],\n",
    "        out_shape=mask_out_shape,\n",
    "        fill=0,\n",
    "        default_value=1\n",
    "    )\n",
    "\n",
    "    return mask_out\n",
    "\n",
    "def plot_mask(mask_plot):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(mask_plot, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def plot_image(image_plot):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(image_plot)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def plot_image_with_mask(image_plot, mask_plot):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Show the image\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(image_plot)\n",
    "\n",
    "    # Create an RGBA version of the mask\n",
    "    mask_rgba = np.zeros((mask_plot.shape[0], mask_plot.shape[1], 4))\n",
    "\n",
    "    # Set color (e.g., red) for mask areas\n",
    "    mask_rgba[..., 0] = 1.0         # Red channel\n",
    "    mask_rgba[..., 3] = mask_plot   # Alpha channel â€” 0 if mask=0, 1 if mask=1\n",
    "\n",
    "    # Overlay the mask\n",
    "    ax.imshow(mask_rgba)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634dbc9552609a16",
   "metadata": {},
   "source": [
    "And now we can load the image and cell segmentation file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9843c15c7d7f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source locations\n",
    "path_image = \"./examples/JupyterPlugin/cell_segmentation_qupath/OS2-ROI.ome.tif\"\n",
    "path_json = \"./examples/JupyterPlugin/cell_segmentation_qupath/OS2-ROI.geojson\"\n",
    "\n",
    "# Load data\n",
    "image = load_tiff(path_image)\n",
    "j = load_json(path_json)\n",
    "\n",
    "# Convert QuPath segmentation to mask\n",
    "mask = extract_mask_from_geojson(j, (image.shape[0], image.shape[1]))\n",
    "\n",
    "# Plot results\n",
    "plot_mask(mask)\n",
    "plot_image(image)\n",
    "plot_image_with_mask(image, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d9176e-d3f0-4792-a67f-46f1976d2a76",
   "metadata": {},
   "source": [
    "Let's push the image and mask to ManiVault:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14365be4da875201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to ManiVault\n",
    "import mvstudio.data\n",
    "mv = mvstudio.data.Hierarchy()\n",
    "\n",
    "# Push image and mask\n",
    "image_mv_ref = mv.addImageItem(image, \"Cell Image\")\n",
    "mask_mv_ref = mv.addImageItem(mask, \"Mask Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec5c318-2341-4169-a17d-85d320d52b0b",
   "metadata": {},
   "source": [
    "Now we want to push a selection based on the mask to ManiVault:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2dae1-cc4a-41f8-bf84-0d76115b7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The internal image indexing in ManiVault is flipped compared to numpy's data model\n",
    "mask_selection = np.flatnonzero(np.flipud(mask) > 0)\n",
    "\n",
    "image_mv_ref.setSelection(mask_selection)\n",
    "mask_mv_ref.setSelection(mask_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59500db0-f47e-486d-b1f0-47ccc5f48a71",
   "metadata": {},
   "source": [
    "We can now visualize the image and mask-selection in ManiVault:\n",
    "\n",
    "Image and mask-selection in ManiVault | Selected subset of the cell data\n",
    "- | -\n",
    "![Image and mask-selection in ManiVault](image_selection_manivault.png) | ![Subset image](image_subset_manivault.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17108fc8-902f-40d4-b167-c78ca2c2188f",
   "metadata": {},
   "source": [
    "We can now interactively select pixels in ManiVault and ask for the selected indices for further analysis on the Python side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06808695-c538-42cd-a9bd-51167a772444",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_selection = image_mv_ref.getSelection()\n",
    "display(manual_selection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ManiVaultStudio",
   "language": "python",
   "name": "manivaultstudio"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": "py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
